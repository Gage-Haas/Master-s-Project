{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "['Albania_Region_Data.txt', 'Greek_Region_Data.txt', 'Japanese_Region_Data.txt', 'korean_Region_Data.txt']\n",
      "Filename : Albania_Region_Data.txt\n",
      "File Path : C:\\Users\\gjhaa\\Desktop\\Masters_Project\\Gene File Manipulations\\Gene_Data\\Isolated_Gene_Data\\Cleaned_Data\\Matched_Data\n",
      "Total Lines in File : 604184\n",
      "Filename : Greek_Region_Data.txt\n",
      "File Path : C:\\Users\\gjhaa\\Desktop\\Masters_Project\\Gene File Manipulations\\Gene_Data\\Isolated_Gene_Data\\Cleaned_Data\\Matched_Data\n",
      "Total Lines in File : 604184\n",
      "Filename : Japanese_Region_Data.txt\n",
      "File Path : C:\\Users\\gjhaa\\Desktop\\Masters_Project\\Gene File Manipulations\\Gene_Data\\Isolated_Gene_Data\\Cleaned_Data\\Matched_Data\n",
      "Total Lines in File : 604184\n",
      "Filename : korean_Region_Data.txt\n",
      "File Path : C:\\Users\\gjhaa\\Desktop\\Masters_Project\\Gene File Manipulations\\Gene_Data\\Isolated_Gene_Data\\Cleaned_Data\\Matched_Data\n",
      "Total Lines in File : 604184\n",
      "(20, 604184)\n",
      "(6, 604184)\n",
      "(29, 604184)\n",
      "(6, 604184)\n"
     ]
    }
   ],
   "source": [
    "# read in already cleaned/matched data from previous code\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import xlrd as xl\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import numpy as np\n",
    "from openpyxl import load_workbook\n",
    "from pandas import ExcelWriter\n",
    "import six\n",
    "import time\n",
    "import pathlib\n",
    "import copy\n",
    "import numpy.matlib \n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "os.chdir(r\"C:\\Users\\gjhaa\\Desktop\\Masters_Project\\Gene File Manipulations\\Gene_Data\\Isolated_Gene_Data\\Cleaned_Data\\Matched_Data\")\n",
    "path = os.getcwd()\n",
    "filepath=os.getcwd()\n",
    "files = os.listdir(u'.')\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "k=1\n",
    "\n",
    "files = [f for f in files if f[-3:] == 'txt']\n",
    "\n",
    "print(files)\n",
    "\n",
    "SetIntersection=[]\n",
    "\n",
    "for i in range(len(files)):\n",
    "    \n",
    "    filename = files[i]\n",
    "    print(\"Filename : \" +str(filename))\n",
    "    print(\"File Path : \" + str(path))\n",
    "\n",
    "    \n",
    "    num_lines = sum(1 for line in open(filename))\n",
    "    f=open(filename,\"r\")\n",
    "\n",
    "\n",
    "    print(\"Total Lines in File : \" +str(num_lines))\n",
    "    #print(\"\\n\\n\")\n",
    "  \n",
    "    lines=f.readlines()\n",
    "    \n",
    "    \n",
    "    if(k==4):\n",
    "        class4 = np.loadtxt(lines, delimiter=',')\n",
    "        k=5\n",
    "    \n",
    "    if(k==3):\n",
    "        class3 = np.loadtxt(lines, delimiter=',')\n",
    "        k=4\n",
    "    \n",
    "    if(k==2):\n",
    "        class2 = np.loadtxt(lines, delimiter=',')\n",
    "        k=3\n",
    "    \n",
    "    if(k==1):\n",
    "        class1 = np.loadtxt(lines, delimiter=',')\n",
    "        k=2\n",
    "                        \n",
    "    f.close()\n",
    "\n",
    "    \n",
    "\n",
    "albanian = class1.T  # FRENCH\n",
    "greek = class2.T     #GREEK\n",
    "japanese=class3.T    #IRANIAN\n",
    "korean=class4.T      #SPANISH\n",
    "print(np.shape(greek))\n",
    "print(np.shape(albanian))\n",
    "print(np.shape(japanese))\n",
    "print(np.shape(korean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of Combined Data is (61, 604184)\n",
      "\n",
      "\n",
      "Only Some of These Calculations Are Printed To Show Examples of Calculations\n",
      "\n",
      "Iteration 0\n",
      "Heterozygous Counts For Individual 0 & For Individual 0 Are 139573\n",
      "Homozygous A Counts For Individual 0 & For Individual 0 Are 0\n",
      "Homozygous B Counts For Individual 0 & For Individual 0 Are 0\n",
      "1.0\n",
      "Heterozygous Counts For Individual 0 & For Individual 1 Are 53968\n",
      "Homozygous A Counts For Individual 0 & For Individual 1 Are 13800\n",
      "Homozygous B Counts For Individual 0 & For Individual 1 Are 13455\n",
      "0.6644423377614715\n",
      "Heterozygous Counts For Individual 0 & For Individual 2 Are 53705\n",
      "Homozygous A Counts For Individual 0 & For Individual 2 Are 13587\n",
      "Homozygous B Counts For Individual 0 & For Individual 2 Are 13818\n",
      "0.6621255085686105\n",
      "[[1.         0.66444234 0.66212551 ... 0.54386701 0.53555356 0.53356349]\n",
      " [0.66444234 1.         0.66379214 ... 0.5368363  0.53121869 0.5336263 ]\n",
      " [0.66212551 0.66379214 1.         ... 0.53909005 0.52887064 0.5316735 ]\n",
      " ...\n",
      " [0.54386701 0.5368363  0.53909005 ... 1.         0.66894211 0.6677299 ]\n",
      " [0.53555356 0.53121869 0.52887064 ... 0.66894211 1.         0.66041102]\n",
      " [0.53356349 0.5336263  0.5316735  ... 0.6677299  0.66041102 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#calculate T1 statistics\n",
    "\n",
    "#related if t1 > 2/3\n",
    "#unrelated and from same populations t1 = 2/3\n",
    "#different populations if t1 < 2/3\n",
    "\n",
    "combined_data=np.vstack((albanian,greek,japanese,korean))\n",
    "print(\"\\nShape of Combined Data is \" + str(np.shape(combined_data)))\n",
    "print(\"\\n\")\n",
    "\n",
    "num_ind = combined_data.shape[0]\n",
    "num_chromosomes = combined_data.shape[1]\n",
    "num_distances = num_ind*num_ind\n",
    "\n",
    "t1_matrix = np.zeros((num_ind, num_ind), dtype= float)\n",
    "#temp = combined_data[i, :]\n",
    "#temp = temp.reshape(num_chromosomes,)\n",
    "#print(temp)\n",
    "#print(np.shape(temp))\n",
    "#print(type(temp))\n",
    "\n",
    "print(\"Only Some of These Calculations Are Printed To Show Examples of Calculations\\n\")\n",
    "\n",
    "for i in range(len(t1_matrix)):\n",
    "    \n",
    "    if i < 1 :\n",
    "        print(\"Iteration \" +str(i))\n",
    "        \n",
    "    for j in range(len(t1_matrix[i])):\n",
    "       # t1_matrix[i][j] = distance.euclidean(centroid_data[i], centroid_data[j]) \n",
    "        ind1 = combined_data[i, :].astype(int)\n",
    "        #ind1=ind1.reshape(num_chromosomes)\n",
    "        ind2 = combined_data[j, :].astype(int)\n",
    "        #ind2=ind2.reshape(num_chromosomes)\n",
    "\n",
    "        homo_countA = 0   #increment if ind1 = 0 and ind2 = 2\n",
    "        homo_countB = 0   #incremenet if ind1 = 2 and ind2 = 0\n",
    "        hetero_count = 0  #increment if ind1 = 1  and ind2 = 1\n",
    "\n",
    "        for x in range(0, num_chromosomes):\n",
    "        \n",
    "          if ind1[x] == 1 and ind2[x] == 1 :\n",
    "\n",
    "            hetero_count += 1\n",
    "\n",
    "          if ind1[x] == 0 and ind2[x] == 2 :\n",
    "\n",
    "            homo_countA += 1\n",
    "\n",
    "          if ind1[x] == 2 and ind2[x] == 0 :\n",
    "\n",
    "            homo_countB += 1\n",
    "      \n",
    "        if i < 1 and j < 3:\n",
    "        \n",
    "            print(\"Heterozygous Counts For Individual \" + str(i) + \" & For Individual \" + str(j) + \" Are \" + str(hetero_count))\n",
    "            print(\"Homozygous A Counts For Individual \" + str(i) + \" & For Individual \" + str(j) + \" Are \" + str(homo_countA))\n",
    "            print(\"Homozygous B Counts For Individual \" + str(i) + \" & For Individual \" + str(j) + \" Are \" + str(homo_countB))\n",
    "        \n",
    "            print(hetero_count/(homo_countA + homo_countB + hetero_count))\n",
    "\n",
    "        \n",
    "        t1_matrix[i][j] = hetero_count/(homo_countA + homo_countB + hetero_count)\n",
    "\n",
    "print(t1_matrix)\n",
    "np.savetxt(\"t1_matrix.csv\", t1_matrix, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[1.        , 0.66444234, 0.66212551, ..., 0.54386701, 0.53555356, 0.53356349],\n",
      "       [0.66444234, 1.        , 0.66379214, ..., 0.5368363 , 0.53121869, 0.5336263 ],\n",
      "       [0.66212551, 0.66379214, 1.        , ..., 0.53909005, 0.52887064, 0.5316735 ],\n",
      "       ...,\n",
      "       [0.54386701, 0.5368363 , 0.53909005, ..., 1.        , 0.66894211, 0.6677299 ],\n",
      "       [0.53555356, 0.53121869, 0.52887064, ..., 0.66894211, 1.        , 0.66041102],\n",
      "       [0.53356349, 0.5336263 , 0.5316735 , ..., 0.6677299 , 0.66041102, 1.        ]])\n"
     ]
    }
   ],
   "source": [
    "#Load T1_Statistic Matrix\n",
    "\n",
    "import pprint as p\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "np.set_printoptions(linewidth=np.inf)\n",
    "t1_matrix = np.loadtxt(\"t1_matrix.csv\", delimiter=',')\n",
    "p.pprint(t1_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.33555766 0.33787449 ... 0.45613299 0.46444644 0.46643651]\n",
      " [0.33555766 0.         0.33620786 ... 0.4631637  0.46878131 0.4663737 ]\n",
      " [0.33787449 0.33620786 0.         ... 0.46090995 0.47112936 0.4683265 ]\n",
      " ...\n",
      " [0.45613299 0.4631637  0.46090995 ... 0.         0.33105789 0.3322701 ]\n",
      " [0.46444644 0.46878131 0.47112936 ... 0.33105789 0.         0.33958898]\n",
      " [0.46643651 0.4663737  0.4683265  ... 0.3322701  0.33958898 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# calculate the dissimilarity matrix\n",
    "\n",
    "disim_matrix = np.zeros((len(t1_matrix), len(t1_matrix)), dtype= float)\n",
    "\n",
    "\n",
    "for i in range(len(t1_matrix)):\n",
    "   \n",
    "    for j in range(len(t1_matrix[i])):\n",
    "\n",
    "        disim_matrix[i][j] = 1 - t1_matrix[i][j]\n",
    "\n",
    "print(disim_matrix)\n",
    "np.savetxt(\"disim_matrix.csv\", disim_matrix, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.00370689 0.00548769 ... 0.02473265 0.02176817 0.01797225]\n",
      " [0.00425111 0.         0.00551384 ... 0.02497643 0.02188989 0.01798804]\n",
      " [0.00428757 0.00642979 0.         ... 0.02497802 0.02197692 0.01803539]\n",
      " ...\n",
      " [0.00951296 0.01116251 0.01265401 ... 0.         0.01414354 0.01187629]\n",
      " [0.00967577 0.01137877 0.01293402 ... 0.00343873 0.         0.01201528]\n",
      " [0.00933153 0.01102373 0.01258751 ... 0.00342722 0.00186455 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# calculate the dissimilarity matrix part2\n",
    "\n",
    "#disim_matrix = np.zeros((len(t1_matrix), len(t1_matrix)), dtype= float)\n",
    "\n",
    "\n",
    "for i in range(len(disim_matrix)):\n",
    "   \n",
    "    for j in range(len(disim_matrix[i])):\n",
    "\n",
    "        disim_matrix[i][j] = np.var(disim_matrix[i] - disim_matrix[j])\n",
    "\n",
    "print(disim_matrix)\n",
    "np.savetxt(\"disim_matrix2.csv\", disim_matrix, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import randint\n",
    "from random import random \n",
    "\n",
    "\n",
    "\n",
    "ss_t = (np.sum(disim_matrix*disim_matrix))/(2*num_ind)\n",
    "\n",
    "num_clusters = 4\n",
    "\n",
    "greeklabels = greek.shape[0]\n",
    "albanianlabels = albanian.shape[0]\n",
    "japaneselabels = japanese.shape[0]\n",
    "koreanlabels = korean.shape[0]\n",
    "Y = np.vstack ((3*np.ones((albanianlabels,1)), 2*np.ones((greeklabels,1)),np.ones((japaneselabels,1)),np.zeros((koreanlabels,1))))\n",
    "#Y represents true class assignments from Data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SSAP Score Is 0.007291402531090903\n",
      "\n",
      "Clustering accuracy is : 39.34426229508197\n",
      "\n",
      "Best SSAP Score Is 0.008215743172240705\n",
      "\n",
      "Clustering accuracy is : 26.229508196721312\n",
      "\n",
      "Best SSAP Score Is 0.01050675057538196\n",
      "\n",
      "Clustering accuracy is : 24.59016393442623\n",
      "\n",
      "Best SSAP Score Is 0.011214266255675141\n",
      "\n",
      "Clustering accuracy is : 34.42622950819672\n",
      "\n",
      "Best SSAP Score Was 0.011214266255675141\n",
      "\n",
      "The Cluster Solution Was Found to be [2, 1, 2, 2, 0, 2, 2, 0, 2, 2, 0, 1, 2, 2, 1, 2, 0, 2, 1, 2, 1, 1, 2, 3, 2, 1, 0, 1, 1, 0, 1, 1, 0, 3, 3, 0, 3, 1, 0, 1, 3, 0, 1, 0, 0, 0, 1, 0, 1, 3, 1, 3, 1, 0, 3, 1, 1, 1, 1, 3, 1]\n",
      "\n",
      "Final Clustering accuracy is : 34.42622950819672\n"
     ]
    }
   ],
   "source": [
    "#GA \n",
    "\n",
    "best_ssap = 0\n",
    "final_solutions = []\n",
    "final_solution_ssap = []\n",
    "\n",
    "for i in range (0, 50):    #iterate genetic algorithm over 50 populations\n",
    "    \n",
    "    solutions = []\n",
    "    solution_ssap = []\n",
    "    offspring =[]\n",
    "    \n",
    "    for z in range(0, 200):  #generate 200 random guesses at cluster solution\n",
    "    \n",
    "        population = []\n",
    "\n",
    "        for x in range (0, num_ind):\n",
    "\n",
    "            population.append(randint(0, num_clusters))  \n",
    "\n",
    "        population = np.asarray(population)               #randomly assign clustering\n",
    "\n",
    "        albanian_indices = np.where(population == 3)[0]    #indices used to pull data from disim matrix based on cluster assignment\n",
    "        greek_indices = np.where(population == 2)[0]\n",
    "        japan_indices = np.where(population == 1)[0]\n",
    "        korean_indices = np.where(population == 0)[0]\n",
    "\n",
    "        albanian_data = disim_matrix[:, albanian_indices]    #pull corresponding cluster matrix data for distances\n",
    "        albanian_data = albanian_data[albanian_indices, :]\n",
    "        greek_data = disim_matrix[:, greek_indices]\n",
    "        greek_data = greek_data[greek_indices, :]\n",
    "        japan_data = disim_matrix[:, japan_indices]\n",
    "        japan_data = japan_data[japan_indices, :]\n",
    "        korean_data = disim_matrix[:, korean_indices]\n",
    "        korean_data = korean_data[korean_indices, :]     \n",
    "\n",
    "        num_albanians = albanian_data.shape[0]\n",
    "        num_greeks = greek_data.shape[0]\n",
    "        num_japanese = japan_data.shape[0]\n",
    "        num_korean = korean_data.shape[0]\n",
    "\n",
    "        ss_wp = (((np.sum(albanian_data*albanian_data)))/(2*num_albanians)) + (((np.sum(greek_data*greek_data)))/(2*num_greeks)) + (((np.sum(japan_data*japan_data)))/(2*num_japanese))+ (((np.sum(korean_data*korean_data)))/(2*num_korean))\n",
    "\n",
    "        ss_ap = ss_t - ss_wp\n",
    "        \n",
    "        solutions.append(population.tolist())   #list of cluster assignments\n",
    "        solution_ssap.append(ss_ap)             # ssap scores\n",
    "    \n",
    "    \n",
    "    if ( i > 0 ) :   #If not first iteration the mutated offspring population gets put into the population with random assignments\n",
    "\n",
    "        solutions = solutions+final_solutions\n",
    "        solutions_ssap = solution_ssap + final_solution_ssap\n",
    "        final_solutions =[]\n",
    "        final_solution_ssap = []\n",
    "\n",
    "        \n",
    "\n",
    "    num_kept_solutions = 75\n",
    "    selected_indices = sorted(range(len(solution_ssap)), key = lambda sub: solution_ssap[sub])[-num_kept_solutions:]   # get indices of best 75 ssap scores\n",
    "    selected_indices = np.asarray(selected_indices)\n",
    "    solutions =  np.asarray(solutions)\n",
    "    selected_clusters = solutions[selected_indices, :]    #get corresponding cluster assignments with best 75 ssap scores\n",
    "    \n",
    "    for a in range(0, len(selected_clusters)):             #single point cross over\n",
    "    \n",
    "        cross_point = randint(0,num_ind)                   #random crossover point    \n",
    "        rand_parent = randint(0,num_kept_solutions)\n",
    "        parent1 = selected_clusters[a, :]                  #each cluster assignment gets to mate\n",
    "        parent2 = selected_clusters[rand_parent, :]        #who they mate with is random\n",
    "        \n",
    "        \n",
    "        offspring1 = np.append(parent1[:cross_point], parent2[cross_point:])        #two offspring produced from crossover point\n",
    "        offspring2 = np.append(parent2[:cross_point], parent1[cross_point:])\n",
    "        offspring.append(offspring1.tolist())\n",
    "        offspring.append(offspring2.tolist())\n",
    "\n",
    "    \n",
    "    for b in range(0, len(offspring)):\n",
    "        \n",
    "        mutation_prob = randint(0, 5)  #20 percent chance of mutation 1/5\n",
    "        \n",
    "        if mutation_prob == 1 :      \n",
    "            \n",
    "            num_mutations = randint(0, num_ind/10)    #number of individual cluster assingments mutated is random\n",
    "            \n",
    "            for c in range(0, num_mutations):\n",
    "            \n",
    "                bit_mutations = randint(0, num_ind)\n",
    "            \n",
    "                offspring[b][bit_mutations] = randint(0,num_clusters)  \n",
    "\n",
    "    #Evaluate mutated offspring\n",
    "    \n",
    "    for d in range(0, len(offspring)):\n",
    "        \n",
    "        final_population = np.asarray(offspring)\n",
    "        np.savetxt(\"final_population.csv\", final_population, delimiter=\",\")\n",
    "\n",
    "        albanian_indices = np.where(final_population[d] == 3)[0]\n",
    "        greek_indices = np.where(final_population[d] == 2)[0]\n",
    "        japan_indices = np.where(final_population[d] == 1)[0]\n",
    "        korean_indices = np.where(final_population[d] == 0)[0]\n",
    "\n",
    "        albanian_data = disim_matrix[:, albanian_indices]\n",
    "        albanian_data = albanian_data[albanian_indices, :]\n",
    "        greek_data = disim_matrix[:, greek_indices]\n",
    "        greek_data = greek_data[greek_indices, :]\n",
    "        japan_data = disim_matrix[:, japan_indices]\n",
    "        japan_data = japan_data[japan_indices, :]\n",
    "        korean_data = disim_matrix[:, korean_indices]\n",
    "        korean_data = korean_data[korean_indices, :]\n",
    "\n",
    "        num_albanians = albanian_data.shape[0]\n",
    "        num_greeks = greek_data.shape[0]\n",
    "        num_japanese = japan_data.shape[0]\n",
    "        num_korean = korean_data.shape[0]\n",
    "\n",
    "        ss_wp = (((np.sum(albanian_data*albanian_data)))/(2*num_albanians)) + (((np.sum(greek_data*greek_data)))/(2*num_greeks)) + (((np.sum(japan_data*japan_data)))/(2*num_japanese))+ (((np.sum(korean_data*korean_data)))/(2*num_korean))\n",
    "\n",
    "        ss_ap = ss_t - ss_wp\n",
    "        \n",
    "        final_solutions = final_population.tolist()\n",
    "        final_solution_ssap.append(ss_ap)             #scores\n",
    "    \n",
    "    max_index = np.argmax(final_solution_ssap, axis=0)   #find index of where ssap score is highest\n",
    "    \n",
    "\n",
    "    if (final_solution_ssap[max_index] > best_ssap):     #compare to current best answer\n",
    "        best_ssap = final_solution_ssap[max_index]\n",
    "        print(\"Best SSAP Score Is \" + str(final_solution_ssap[max_index]))\n",
    "        cluster_solution =[]\n",
    "        cluster_solution = final_solutions[max_index]\n",
    "        \n",
    "        #test accuracy of answer\n",
    "\n",
    "        Y_test = Y.tolist()\n",
    "        \n",
    "        Y_test = sum(Y_test, []) \n",
    "        Y_test = [int(i) for i in Y_test] \n",
    "        \n",
    "        correct_counter = 0\n",
    "        for e in range(0, num_ind):\n",
    "            if(Y_test[e] == cluster_solution[e]):\n",
    "                correct_counter+=1\n",
    "        \n",
    " \n",
    "        accuracy = (correct_counter/num_ind)*100    \n",
    "\n",
    "        print(\"\\nClustering accuracy is : \" + str(accuracy) +\"\\n\")       \n",
    "        \n",
    "    \n",
    "print(\"Best SSAP Score Was \" + str(best_ssap))    \n",
    "print(\"\\nThe Cluster Solution Was Found to be \" + str(cluster_solution))\n",
    "\n",
    "tcorrect_counter = 0\n",
    "\n",
    "for i in range(num_ind):\n",
    "    test_equality  = np.equal(Y[i], cluster_solution[i]) \n",
    "\n",
    "    if(all(test_equality)) :\n",
    "        tcorrect_counter += 1\n",
    "            \n",
    "test_accuracy = (tcorrect_counter/num_ind)*100    \n",
    "\n",
    "print(\"\\nFinal Clustering accuracy is : \" + str(test_accuracy))\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
